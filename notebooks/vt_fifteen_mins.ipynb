{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is c:\\Users\\blond\\Documents\\NssProjects\\accre-green-bean-casserole\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.chdir('..')\n",
    "print(f'Current working directory is {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts.get import log_to_df, df_to_datelist\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv(\"data/fullsample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = jobs[jobs['END'] != 'Unknown']\n",
    "jobs = jobs[jobs['STATE'] == 'COMPLETED']\n",
    "jobs['BEGIN'] = pd.to_datetime(jobs['BEGIN'])\n",
    "jobs['END'] = pd.to_datetime(jobs['END'])\n",
    "jobs['REQTIME'] = pd.to_timedelta(jobs['REQTIME'])\n",
    "jobs['USEDTIME'] = pd.to_timedelta(jobs['USEDTIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce5 = log_to_df('data/slurm_wrapper_ce5.log')\n",
    "ce6 = log_to_df('data/slurm_wrapper_ce6.log')\n",
    "\n",
    "errors_ce6 = df_to_datelist(ce6)\n",
    "errors_ce5 = df_to_datelist(ce5)\n",
    "all_errors = errors_ce5 + errors_ce6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_jobs_before_interr(all_errors_func = all_errors, jobs_func = jobs, typeTime = 'h', countTime = 1, on = 'END'):\n",
    "    \"\"\"\n",
    "    Calculates the number of jobs occurring within a specified time window \n",
    "    relative to each error timestamp, based on the relationship specified \n",
    "    (BEGIN, DURING, END, or ALL). Returns a DataFrame where each row corresponds \n",
    "    to an error and the number of jobs meeting the specified criteria.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    all_errors : pd.Series or iterable\n",
    "        A list or Series of error timestamps. Each timestamp is used as \n",
    "        a reference point to count the jobs within the specified time window.\n",
    "\n",
    "    jobs : pd.DataFrame\n",
    "        A DataFrame containing job details with at least the following columns:\n",
    "        - 'BEGIN': The start times of jobs.\n",
    "        - 'END': The end times of jobs.\n",
    "\n",
    "    typeTime : str, optional\n",
    "        The unit of time for the countTime parameter. Accepted values are:\n",
    "        - 'm': Minutes\n",
    "        - 'h': Hours (default)\n",
    "        - 'd': Days\n",
    "\n",
    "    countTime : float, optional\n",
    "        The size of the time window in the units specified by typeTime. \n",
    "        For example:\n",
    "        - countTime=1 with typeTime='h' means a 1-hour window.\n",
    "        - countTime=30 with typeTime='m' means a 30-minute window.\n",
    "\n",
    "    on : str, optional\n",
    "        Defines the relationship between the jobs and the error timestamp. \n",
    "        Accepted values are:\n",
    "        - 'BEGIN': Count jobs whose start times fall within the time window \n",
    "                   before the error.\n",
    "        - 'DURING': Count jobs that were active (spanning) during the error.\n",
    "        - 'END': Count jobs whose end times fall within the time window \n",
    "                 before the error. (Default)\n",
    "        - 'ALL': Generates a DataFrame with counts for all relationships:\n",
    "            - 'Start Count': Number of jobs starting within the time window.\n",
    "            - 'During Count': Number of jobs spanning the error timestamp.\n",
    "            - 'End Count': Number of jobs ending within the time window.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        - For 'BEGIN', 'DURING', or 'END': A DataFrame where each row corresponds \n",
    "          to an error and its associated count of jobs based on the specified criteria.\n",
    "        - For 'ALL': A DataFrame with columns 'Interruption Time', 'Start Count', \n",
    "          'During Count', and 'End Count'.\n",
    "\n",
    "    Notes:\n",
    "    -----\n",
    "    - If an invalid value for `on` is provided, the function defaults to 'END' \n",
    "      and prints a warning message.\n",
    "    - The 'ALL' option adds comprehensive job counts across all specified \n",
    "      relationships to the error timestamps.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#     error_min_time = all_errors.min() - pd.Timedelta(hours=time_hours)\n",
    "#         error_max_time = all_errors.max()\n",
    "\n",
    "#          Filter jobs within the global range\n",
    "#         jobs_filtered = jobs[(jobs['BEGIN'] <= error_max_time) & (jobs['END'] >= error_min_time)]\n",
    "    \n",
    "    time_dict = {\n",
    "        'm': 60,\n",
    "        'h': 1,\n",
    "        'd': 1/24    \n",
    "    }\n",
    "    time_hours = countTime / time_dict[typeTime]\n",
    "    error_min_time = min(all_errors) - pd.Timedelta(hours=time_hours)\n",
    "    error_max_time = max(all_errors)\n",
    "    on = on.strip().upper()\n",
    "    errors_array = np.array(all_errors_func)\n",
    "    all_errors_func = sorted(all_errors_func)\n",
    "    \n",
    "    if on == 'BEGIN':\n",
    "        \n",
    "        jobs_copy = jobs_func.copy(deep = True)\n",
    "        jobs_copy = jobs_copy[(jobs_copy['BEGIN'] <= error_max_time) & (jobs_copy['BEGIN'] >= error_min_time)]\n",
    "        jobs_copy = jobs_copy.sort_values('BEGIN')\n",
    "        job_counts_for_interrupt = {}\n",
    "        last_error_date = all_errors_func[0]\n",
    "        for i, error in enumerate(tqdm(all_errors_func, desc=\"Processing Errors\")):\n",
    "            hour_less_than_given = error - pd.Timedelta(hours=time_hours)\n",
    "            if (error - last_error_date).days >= 30:\n",
    "                jobs_copy = jobs_copy[jobs_copy['BEGIN'] >= hour_less_than_given]\n",
    "                print(last_error_date)\n",
    "                last_error_date = error\n",
    "                \n",
    "            \n",
    "            count = ((jobs_copy['BEGIN'] > hour_less_than_given) & (jobs_copy['BEGIN'] <= error)).sum()\n",
    "            job_counts_for_interrupt[error] = count\n",
    "    \n",
    "    elif on == 'DURING':\n",
    "        \n",
    "        jobs_copy = jobs_func.copy(deep = True)\n",
    "        jobs_copy = jobs_copy[(jobs_copy['BEGIN'] <= error_max_time) & (jobs_copy['END'] >= error_min_time)]\n",
    "        jobs_copy = jobs_copy.sort_values('END')\n",
    "        job_counts_for_interrupt = {}\n",
    "        last_error_date = all_errors_func[0]\n",
    "        for i, error in enumerate(tqdm(all_errors_func, desc=\"Processing Errors\")):\n",
    "            hour_less_than_given = error - pd.Timedelta(hours=time_hours)\n",
    "            if (error - last_error_date).days >= 30:\n",
    "                jobs_copy = jobs_copy[jobs_copy['END'] >= error]\n",
    "                print(last_error_date)\n",
    "                last_error_date = error\n",
    "            #hour_less_than_given = error - pd.Timedelta(hours=time_hours)\n",
    "            count = ((jobs_copy['END'] > error) & (jobs_copy['BEGIN'] < error)).sum()\n",
    "            job_counts_for_interrupt[error] = count\n",
    "            \n",
    "    elif on == 'END':\n",
    "        \n",
    "        jobs_copy = jobs_func.copy(deep = True)\n",
    "        jobs_copy = jobs_copy[(jobs_copy['END'] <= error_max_time) & (jobs_copy['END'] >= error_min_time)]\n",
    "        jobs_copy = jobs_copy.sort_values('END')\n",
    "        job_counts_for_interrupt = {}\n",
    "        last_error_date = all_errors_func[0]\n",
    "        for i, error in enumerate(tqdm(all_errors_func, desc=\"Processing Errors\")):\n",
    "            hour_less_than_given = error - pd.Timedelta(hours=time_hours)\n",
    "            if (error - last_error_date).days >= 30:\n",
    "                jobs_copy = jobs_copy[jobs_copy['END'] >= hour_less_than_given]\n",
    "                print(last_error_date)\n",
    "                last_error_date = error\n",
    "            hour_less_than_given = error - pd.Timedelta(hours=time_hours)\n",
    "            count = ((jobs_copy['END'] > hour_less_than_given) & (jobs_copy['END'] <= error)).sum()\n",
    "            job_counts_for_interrupt[error] = count\n",
    "        \n",
    "    elif on == 'ALL':\n",
    "        \n",
    "        jobs_copy = jobs_func.copy(deep = True)\n",
    "        jobs_copy = jobs_copy[((jobs_copy['END'] <= error_max_time) & (jobs_copy['END'] >= error_min_time)) | ((jobs_copy['BEGIN'] <= error_max_time) & (jobs_copy['BEGIN'] >= error_min_time)) | ((jobs_copy['BEGIN'] <= error_max_time) & (jobs_copy['END'] >= error_min_time))]\n",
    "        jobs_copy = jobs_copy.sort_values('END')\n",
    "        \n",
    "        job_counts_for_interrupt_begin = {}\n",
    "        job_counts_for_interrupt_during = {}\n",
    "        job_counts_for_interrupt_end = {}\n",
    "        last_error_date = all_errors_func[0]\n",
    "\n",
    "        for i, error in enumerate(tqdm(all_errors_func, desc=\"Processing Errors\")):\n",
    "            hour_less_than_given = error - pd.Timedelta(hours=time_hours)\n",
    "            if (error - last_error_date).days >= 30:\n",
    "                jobs_copy = jobs_copy[jobs_copy['END'] >= hour_less_than_given]\n",
    "                print(last_error_date)\n",
    "                last_error_date = error\n",
    "\n",
    "            countbegin = ((jobs_copy['BEGIN'] > hour_less_than_given) & (jobs_copy['BEGIN'] <= error)).sum()\n",
    "            countduring = ((jobs_copy['END'] > error) & (jobs_copy['BEGIN'] < error)).sum()\n",
    "            countend = ((jobs_copy['END'] > hour_less_than_given) & (jobs_copy['END'] <= error)).sum()\n",
    "            \n",
    "            job_counts_for_interrupt_begin[error] = countbegin\n",
    "            job_counts_for_interrupt_during[error] = countduring\n",
    "            job_counts_for_interrupt_end[error] = countend\n",
    "            \n",
    "        df1 =  pd.DataFrame(job_counts_for_interrupt_begin.items())\n",
    "        #df.rename(columns={'A': 'a', 'B': 'c'}, inplace=True)\n",
    "        df1.rename(columns = {1:'Start Count', 0:'Interruption Time'}, inplace = True)\n",
    "        df1['During Count'] = job_counts_for_interrupt_during.values()\n",
    "        df1['End Count'] = job_counts_for_interrupt_end.values()\n",
    "        \n",
    "        return df1\n",
    "        \n",
    "            \n",
    "    else:\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f'Your \"ON\" variable of \"{on}\" was not found to be (BEGIN, END, DURING, or ALL), so defaulted to END.')\n",
    "        \n",
    "        jobs_copy = jobs_func.copy(deep = True)\n",
    "        jobs_copy = jobs_copy[(jobs_copy['END'] <= error_max_time) & (jobs_copy['END'] >= error_min_time)]\n",
    "        jobs_copy = jobs_copy.sort_values('END')\n",
    "        job_counts_for_interrupt = {}\n",
    "        last_error_date = all_errors_func[0]\n",
    "        for i, error in enumerate(tqdm(all_errors_func, desc=\"Processing Errors\")):\n",
    "            hour_less_than_given = error - pd.Timedelta(hours=time_hours)\n",
    "            if (error - last_error_date).days >= 30:\n",
    "                jobs_copy = jobs_copy[jobs_copy['END'] >= hour_less_than_given]\n",
    "                print(last_error_date)\n",
    "                last_error_date = error\n",
    "            hour_less_than_given = error - pd.Timedelta(hours=time_hours)\n",
    "            count = ((jobs_copy['END'] > hour_less_than_given) & (jobs_copy['END'] <= error)).sum()\n",
    "            job_counts_for_interrupt[error] = count\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(job_counts_for_interrupt.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7375084 entries, 1 to 7395884\n",
      "Data columns (total 12 columns):\n",
      " #   Column     Dtype          \n",
      "---  ------     -----          \n",
      " 0   JOBID      object         \n",
      " 1   STATE      object         \n",
      " 2   BEGIN      datetime64[ns] \n",
      " 3   END        datetime64[ns] \n",
      " 4   REQMEM     object         \n",
      " 5   USEDMEM    object         \n",
      " 6   REQTIME    timedelta64[ns]\n",
      " 7   USEDTIME   timedelta64[ns]\n",
      " 8   NODES      int64          \n",
      " 9   CPUS       int64          \n",
      " 10  PARTITION  object         \n",
      " 11  EXITCODE   object         \n",
      "dtypes: datetime64[ns](2), int64(2), object(6), timedelta64[ns](2)\n",
      "memory usage: 731.5+ MB\n"
     ]
    }
   ],
   "source": [
    "jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors:   3%|▎         | 93/3296 [00:07<09:03,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-18 06:16:25.392946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors:  35%|███▍      | 1146/3296 [01:07<05:50,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-18 15:03:14.439449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors:  49%|████▉     | 1616/3296 [01:32<03:13,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 15:18:59.450549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors:  53%|█████▎    | 1735/3296 [01:38<02:59,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-17 16:28:49.469932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors:  63%|██████▎   | 2062/3296 [01:53<02:10,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-16 16:58:11.049951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors:  67%|██████▋   | 2193/3296 [01:58<01:21, 13.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-19 08:29:39.070946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors:  79%|███████▉  | 2613/3296 [02:14<00:35, 19.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-18 14:59:17.312041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors:  85%|████████▍ | 2792/3296 [02:20<00:24, 20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-20 08:10:47.902061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors:  92%|█████████▏| 3047/3296 [02:28<00:13, 18.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-19 11:57:52.170544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors:  95%|█████████▌| 3139/3296 [02:30<00:05, 28.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-19 12:36:10.601915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors:  99%|█████████▉| 3267/3296 [02:32<00:00, 85.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-20 12:03:28.102533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors: 100%|██████████| 3296/3296 [02:33<00:00, 21.54it/s] \n"
     ]
    }
   ],
   "source": [
    "Every_Fifteen_Minutes_Errors_df = count_jobs_before_interr(typeTime = 'm', countTime = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Every_Fifteen_Minutes_Errors_df[0] = pd.to_datetime(Every_Fifteen_Minutes_Errors_df[0])\n",
    "Every_Fifteen_Minutes_Errors_df.set_index(0, inplace=True)\n",
    "Every_Fifteen_Minutes_Errors_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-28 09:45:00</td>\n",
       "      <td>9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-11 09:45:00</td>\n",
       "      <td>6712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-11 09:00:00</td>\n",
       "      <td>6696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-21 18:30:00</td>\n",
       "      <td>5747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-08-03 21:00:00</td>\n",
       "      <td>4587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>2020-11-23 11:30:00</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>2021-02-06 08:15:00</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>2021-09-09 11:00:00</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>2021-03-21 16:15:00</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>2021-01-17 02:00:00</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1285 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0     1\n",
       "0    2021-06-28 09:45:00  9890\n",
       "1    2020-12-11 09:45:00  6712\n",
       "2    2020-12-11 09:00:00  6696\n",
       "3    2020-11-21 18:30:00  5747\n",
       "4    2021-08-03 21:00:00  4587\n",
       "...                  ...   ...\n",
       "1280 2020-11-23 11:30:00   101\n",
       "1281 2021-02-06 08:15:00   101\n",
       "1282 2021-09-09 11:00:00   101\n",
       "1283 2021-03-21 16:15:00   101\n",
       "1284 2021-01-17 02:00:00   101\n",
       "\n",
       "[1285 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Group_By_Day_df= Every_Fifteen_Minutes_Errors_df.groupby(pd.Grouper(key=0, freq='15min')).sum()\n",
    "\n",
    "Group_By_Day_df[Group_By_Day_df[1] > 100].sort_values(1, ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=33926, minmax=(array([0], dtype=int64), array([9890], dtype=int64)), mean=array([16.67956729]), variance=array([19293.52387844]), skewness=array([27.57957353]), kurtosis=array([1306.70503834]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "stats.describe(Group_By_Day_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_jobs_before_interr_mean(all_errors_func = all_errors, jobs_func = jobs, typeTime = 'h', countTime = 1, on = 'END'):\n",
    "    \n",
    "    time_dict = {\n",
    "        'm': 60,\n",
    "        'h': 1,\n",
    "        'd': 1/24    \n",
    "    }\n",
    "    time_hours = countTime / time_dict[typeTime]\n",
    "    error_min_time = min(all_errors_func) - pd.Timedelta(hours=time_hours)\n",
    "    error_max_time = max(all_errors_func)\n",
    "    \n",
    "    jobs_copy = jobs_func.copy(deep = True)\n",
    "    jobs_copy = jobs_copy[(jobs_copy['END'] <= error_max_time) & (jobs_copy['END'] >= error_min_time)]\n",
    "    jobs_copy = jobs_copy.sort_values('END')\n",
    "    job_counts_for_interrupt = {}\n",
    "    last_error_date = all_errors_func[0]\n",
    "    \n",
    "    for error in tqdm(sorted(all_errors_func), desc=\"Processing Errors\"):\n",
    "        hour_less_than_given = error - pd.Timedelta(hours=time_hours)\n",
    "        if (error - last_error_date).days >= 30:\n",
    "            jobs_copy = jobs_copy[jobs_copy['END'] >= hour_less_than_given]\n",
    "            last_error_date = error\n",
    "            \n",
    "        count = ((jobs_copy['END'] > hour_less_than_given) & (jobs_copy['END'] <= error)).sum()\n",
    "        job_counts_for_interrupt[error] = count\n",
    "    \n",
    "    result_df = pd.DataFrame(job_counts_for_interrupt.items())\n",
    "    mean_jobs = result_df[1].mean()\n",
    "    \n",
    "    print(f\"\\nAverage Number of Jobs Completed in {countTime}{typeTime} Before Error Ocurred: {mean_jobs:.2f}\")\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Errors: 100%|██████████| 3296/3296 [02:21<00:00, 23.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Number of Jobs Completed in 15m Before Error Ocurred: 171.68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-18 06:16:25.392946</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-18 06:38:44.172473</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-18 06:53:44.272915</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-18 06:54:04.322412</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-18 07:47:25.825172</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3291</th>\n",
       "      <td>2021-09-24 18:14:35.862916</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292</th>\n",
       "      <td>2021-09-24 19:13:14.894282</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>2021-10-02 08:14:16.557499</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>2021-10-02 18:29:08.267199</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3295</th>\n",
       "      <td>2021-10-06 15:39:20.269943</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3296 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0    1\n",
       "0    2020-10-18 06:16:25.392946   51\n",
       "1    2020-10-18 06:38:44.172473   67\n",
       "2    2020-10-18 06:53:44.272915   70\n",
       "3    2020-10-18 06:54:04.322412   70\n",
       "4    2020-10-18 07:47:25.825172   67\n",
       "...                         ...  ...\n",
       "3291 2021-09-24 18:14:35.862916  150\n",
       "3292 2021-09-24 19:13:14.894282  123\n",
       "3293 2021-10-02 08:14:16.557499  130\n",
       "3294 2021-10-02 18:29:08.267199  216\n",
       "3295 2021-10-06 15:39:20.269943    3\n",
       "\n",
       "[3296 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_jobs_before_interr_mean(typeTime = 'm', countTime = 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
